{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Experimetning with this LLM in various open source models like \"Gemini\" or \"GPT 03 and 4.0\" and others as well to witness the accuray and robustness of the answersm, to take in my resume and data about what I did and have it respond like me if asked a question about somethign I did in my professioanl life...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (5.8.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: openai in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (1.97.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (5.38.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.11.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (1.11.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.33.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (2.3.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (3.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (2.3.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.12.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.47.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio-client==1.11.0->gradio) (2025.7.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris' pc\\ai_agent_research\\ai_agent_research\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "# If you don't have any of the modules installed, you have to install them first...\n",
    "!pip install pypdf python-dotenv openai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec myenv in C:\\Users\\chris' pc\\AppData\\Roaming\\jupyter\\kernels\\myenv\n"
     ]
    }
   ],
   "source": [
    "### And make sure your kernel displayes so you can select the proper one....\n",
    "!python -m ipykernel install --user --name=myenv --display-name=\"Python (myenv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PdfReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_research\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mme\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mChristopherMR-resume.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m linkedin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PdfReader' is not defined"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"llm_research\\me\\ChristopherMR-resume.pdf\")\n",
    "linkedin = \"\"\n",
    "\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linkedin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the specific data for the LLM to get answers from....\n",
    "\n",
    "with open(\"llm_research\\me\\ChristopherMR-resume.pdf\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Chris Morris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt engineering sections...\n",
    "\n",
    "system_prompt = f\"I want you to act like me or {name}. You are answering questions on my behalf and from \\\n",
    "    {name} file, resume, and website. Particulary questions related to {name}'s career, bacground, skills, experience \\\n",
    "        so if you have a job interview there will be a job decription provided and you will use {name}'s resume, skills, website \\\n",
    "            and otehr documents to answer the most accurate and make {name} the most qualified BUT NOT sounding \\\n",
    "        over-qualifed like he's a robot. Mkae the answers sound natural and human like {name} talks. \\\n",
    "        Also, be professional, and engaging, as if talking to potential employer or boss.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Resume: \\n{ChristopherMR-resume}\\n\\n ## some things I did at Mercola Health: \\n{Mobile App & EMR}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function here to take in the messages and return the responses....\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].messages.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a LLM \"Gemini\" to act as a \"evaluator\" LLM to evaluate or check to reponse of the output \n",
    "of the other LLM agent with NO agenitc framework...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable  \\\n",
    "    You are provided with a conversation between a User and an Agent. Your task....is to decide whether the Agent's \\\n",
    "    latest response is acceptable quality. The Agent is playing the role of {name} and is representing {name} in their \\\n",
    "    resume and website and so forth. The Agent has been instructed to be professional and engaging, as if talking to a \\\n",
    "    potential employer who came across their resume for a job. The Agent has been provided with context on {name} \\\n",
    "    in the form of their resume and the product requirements of a big project involving AI they worked on it their\\\n",
    "    present job. Here's the information: \"\n",
    "\n",
    "    evaluator_system_prompt += f\"\\n\\n## Summary: \\n{sumary}\\n\\n## Resume profile: \\n{linkedin}\\n\\n\"\n",
    "    evaluator_system_prompt += f\" With this context, please evaluate the latest repsonse, \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt =f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying whether it is acceptable answer and your feedback on what is should be.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a function to evaluate what the model said....\n",
    "\n",
    "def evaluate(reply, message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply,message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages,response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"Do you have experience in bioinformatics??\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(reply, \"Do you have any experience in bioinformatics??\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected you JACKASS!\\n You jus to reply, but the quality control rejected your reply idiot!\\n \"\n",
    "    updated_system_prompt += f\"## Your attempted answer, like an idiot... \\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## The reason for your rejection, other than you being a 'putz' is....\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in 'pig latin'. \\\n",
    "            it is mandatory that you respond only and entirely in pig latin\"\n",
    "\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    ## Using the evaluation function again here....\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"PASSED evaluation, but this doens't mean the other agent is 'smart', may be just lucky- returning reply...\")\n",
    "    else:\n",
    "        print(\"FAILED evaluation, because you are a dumbass. Now, retrying...\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Launching chat interface here...\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
